// --------------------------------------
// Code generated by ChatGPT model o1 pro
// --------------------------------------

import { getEscapeVelocity, getJuliaSeries } from "./julia.js";
import { getMapState } from "./map.js";
import { canvas, ctx } from "./state.js";

// Offscreen canvas + context
let offscreenCanvas = null;
let offscreenGpuContext = null;

// WEBGPU device/pipeline/buffer objects
let gpuDevice = null;
let gpuPipeline = null;
let gpuUniformBuffer = null;
let gpuReferenceOrbitBuffer = null;
let gpuBindGroup = null;

const MAX_ITERATIONS = 500; // can increase for deeper zoom if desired

/**
 * Attempt to find a point in the current view whose orbit does NOT escape quickly.
 * We'll do a simple random search of up to maxSamples tries.
 */
function findOrbit(centerX, centerY, zoom, width, height, maxSamples = 200) {
    const scaleFactor = (4.0 / width) * Math.pow(2.0, -zoom);

    for (let s = 0; s < maxSamples; s++) {
        const sx = Math.random();
        const sy = Math.random();

        // Convert pixel coords -> complex plane
        const candidateX = centerX + (sx - 0.5) * width * scaleFactor;
        const candidateY = centerY - (sy - 0.5) * height * scaleFactor;

        const iters = getEscapeVelocity(candidateX, candidateY, MAX_ITERATIONS);
        if (iters >= MAX_ITERATIONS) {
            return { x: sx * width, y: sy * height, iters: getJuliaSeries(candidateX, candidateY, MAX_ITERATIONS) };
        }
    }

    console.warn("Could not find a 'good' orbit. Fallback to center.");
    return { x: 0.5 * width, y: 0.5 * height, iters: getJuliaSeries(centerX, centerY, MAX_ITERATIONS) };
}

/**
 * Initialize WebGPU context/pipeline if supported
 */
export async function initWebGPU() {
    try {
        if (!('gpu' in navigator)) {
            console.warn('WebGPU not supported in this browser.');
            return false;
        }

        const adapter = await navigator.gpu.requestAdapter();
        if (!adapter) {
            console.warn('Failed to get GPU adapter.');
            return false;
        }

        gpuDevice = await adapter.requestDevice();
        if (!gpuDevice) {
            console.warn('Failed to request GPU device.');
            return false;
        }

        // ----------------------------------------------
        // 1. Create a hidden offscreen canvas + context
        // ----------------------------------------------
        offscreenCanvas = document.createElement('canvas');
        offscreenCanvas.style.display = 'none';
        document.body.appendChild(offscreenCanvas);

        offscreenGpuContext = offscreenCanvas.getContext('webgpu');
        if (!offscreenGpuContext) {
            console.warn('Could not get WebGPU context for offscreen canvas.');
            return false;
        }

        // Choose a preferred canvas format
        const format = navigator.gpu.getPreferredCanvasFormat();

        // Create our render pipeline
        gpuPipeline = gpuDevice.createRenderPipeline({
            layout: 'auto',
            vertex: {
                module: gpuDevice.createShaderModule({
                    code: wgslVertexShader
                }),
                entryPoint: 'main'
            },
            fragment: {
                module: gpuDevice.createShaderModule({
                    code: wgslFragmentShader
                }),
                entryPoint: 'main',
                targets: [{ format }]
            },
            primitive: {
                topology: 'triangle-strip',
                stripIndexFormat: undefined
            }
        });

        // Create a buffer for the uniform data.
        // We'll store centerX, centerY, scale, plus some padding, plus resolution as f32x2.
        gpuUniformBuffer = gpuDevice.createBuffer({
            size: 24,
            usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
        });

        // Create a buffer for the reference orbit data. We'll allocate enough for
        // 2 floats * MAX_ITERATIONS = 2*4*MAX_ITERATIONS bytes.
        const orbitBufferSize = 2 * 4 * MAX_ITERATIONS;
        gpuReferenceOrbitBuffer = gpuDevice.createBuffer({
            size: orbitBufferSize,
            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST
        });

        gpuBindGroup = gpuDevice.createBindGroup({
            layout: gpuPipeline.getBindGroupLayout(0),
            entries: [
                {
                    binding: 0,
                    resource: {
                        buffer: gpuUniformBuffer
                    }
                },
                {
                    binding: 1,
                    resource: {
                        buffer: gpuReferenceOrbitBuffer
                    }
                }
            ]
        });

        return true;
    } catch (error) {
        console.warn(error);
        return false;
    }
}

/**
 * Render fractal with WebGPU into an offscreen canvas, then blit to the visible canvas.
 */
export function renderFractalWebGPU(scale = 1) {
    if (!gpuDevice || !gpuPipeline || !offscreenGpuContext) {
        console.error("WebGPU context not initialized properly");
        return;
    }

    // ------------------------------------
    // 2. Configure our offscreen canvas
    // ------------------------------------
    // We'll match the final size * scale. For example, if our main canvas is 800x600
    // and scale=0.5, then offscreen is 400x300, etc.
    const w = Math.floor(canvas.width * scale);
    const h = Math.floor(canvas.height * scale);

    offscreenCanvas.width = w;
    offscreenCanvas.height = h;

    const format = navigator.gpu.getPreferredCanvasFormat();
    offscreenGpuContext.configure({
        device: gpuDevice,
        format: format,
        alphaMode: 'premultiplied'
    });

    // ------------------------------------
    // 3. Write fractal parameters to GPU
    // ------------------------------------
    const state = getMapState();
    const usePerturbation = state.zoom > 16;
    const orbit = usePerturbation ? findOrbit(state.x, state.y, state.zoom, w, h) : undefined;

    const uniformArray = new ArrayBuffer(24);
    const dataView = new DataView(uniformArray);
    dataView.setUint32(0, usePerturbation ? 1 : 0, true);            // use_perturbation
    dataView.setFloat32(4, state.zoom, true);  // zoom
    dataView.setFloat32(8, orbit ? orbit.x : state.x, true);     // center
    dataView.setFloat32(12, orbit ? orbit.y : state.y, true);     // center
    dataView.setFloat32(16, w, true);           // resolution
    dataView.setFloat32(20, h, true);           // resolution

    gpuDevice.queue.writeBuffer(gpuUniformBuffer, 0, uniformArray);

    if (orbit) {
        gpuDevice.queue.writeBuffer(gpuReferenceOrbitBuffer, 0, orbit.iters);
    }

    // Acquire a texture to render into (offscreen)
    const renderView = offscreenGpuContext.getCurrentTexture().createView();

    // Build the command pass
    const commandEncoder = gpuDevice.createCommandEncoder();
    const passEncoder = commandEncoder.beginRenderPass({
        colorAttachments: [
            {
                view: renderView,
                clearValue: { r: 0, g: 0, b: 0, a: 1 },
                loadOp: 'clear',
                storeOp: 'store',
            },
        ],
    });

    passEncoder.setPipeline(gpuPipeline);
    passEncoder.setBindGroup(0, gpuBindGroup);
    passEncoder.draw(4, 1, 0, 0); // 4 verts => full-screen quad
    passEncoder.end();

    const gpuCommands = commandEncoder.finish();
    gpuDevice.queue.submit([gpuCommands]);

    // ------------------------------------
    // 4. Blit from offscreen -> main canvas
    // ------------------------------------
    // Use the main canvas's 2D context to draw the offscreen image:
    // If you want a simple "centered" or "fit" approach, you can do:
    ctx.save();
    ctx.scale(1 / scale, 1 / scale);
    ctx.drawImage(offscreenCanvas, 0, 0);
    ctx.restore();
}

/* ---------------------------------------------------------
 * WGSL Shaders (updated to model complex numbers as vec2<f32>)
 * --------------------------------------------------------- */

const wgslVertexShader = /* wgsl */ `
@vertex
fn main(@builtin(vertex_index) vertexIndex : u32) -> @builtin(position) vec4f {
    // We'll draw 2 triangles that cover the entire clip space:
    //   vertexIndex: 0,1,2,3 => positions in a strip
    let x = f32((vertexIndex & 1u) << 1u) - 1.0; // 0->-1, 1->1, 2->-1, 3->1
    let y = f32((vertexIndex & 2u)) - 1.0;      // 0->-1, 1->-1, 2->1, 3->1
    return vec4f(x, y, 0.0, 1.0);
}
`;

const wgslFragmentShader = /* wgsl */ `
struct FractalUniforms {
    use_perturbation: u32,
    zoom            : f32,
    center          : vec2<f32>,
    resolution      : vec2<f32>,
};

const MAX_ITERATIONS : u32 = ${MAX_ITERATIONS};

@group(0) @binding(0)
var<uniform> u : FractalUniforms;

@group(0) @binding(1)
var<storage, read> referenceOrbit : array<vec2<f32>, MAX_ITERATIONS>;

// Function to perform complex square using vec2<f32> to represent complex numbers.
fn complex_square(a: vec2<f32>) -> vec2<f32> {
    return vec2<f32>(
        a.x * a.x - a.y * a.y,  // real part
        2.0 * a.x * a.y         // imaginary part
    );
}

// Function to perform complex square using vec2<f32> to represent complex numbers.
fn complex_mul(a: vec2<f32>, b: vec2<f32>) -> vec2<f32> {
    return vec2<f32>(
        a.x * b.x - a.y * b.y,  // real part
        a.x * b.y + a.y * b.x   // imaginary part
    );
}

fn get_escape_velocity(c: vec2<f32>) -> u32 {
    var z: vec2<f32> = vec2<f32>(0.0, 0.0);
    for (var i = 0u; i < MAX_ITERATIONS; i = i + 1u) {
        // Compute z = z * z + c, where z * z is computed using complex multiplication.
        z = complex_square(z) + c;

        // If the magnitude of z exceeds 2.0 (i.e., dot(z,z) > 4.0), the point escapes.
        if (dot(z, z) > 4.0) {
            return i;
        }
    }
    return MAX_ITERATIONS;
}

fn get_escape_velocity_perturb(delta0: vec2<f32>) -> u32 {
    // We'll do a loop up to MAX_ITERATIONS, reading the reference Xₙ and
    // iterating ∆ₙ = Yₙ - Xₙ.
    var delta = delta0;

    for (var i = 0u; i < MAX_ITERATIONS; i = i + 1u) {
        let Xn = referenceOrbit[i];
        // ∆ₙ₊₁ = (2 * Xₙ + ∆ₙ) * ∆ₙ + ∆₀
        delta = complex_mul(2.0 * Xn + delta, delta) + delta0;

        if (dot(delta, delta) > 4.0) {
            return i;
        }
    }
    return MAX_ITERATIONS;
}

@fragment
fn main(@builtin(position) fragCoord: vec4f) -> @location(0) vec4f {
    let scaleFactor = 4.0 / u.resolution.x * exp2(-u.zoom) * vec2<f32>(1, -1);

    // Standard Mandelbrot iteration using complex arithmetic
    var escapeValue = 0u;
    if u.use_perturbation == 0 {
        // Convert from pixel coords -> fractal coordinates
        // Here we model the fractal coordinate as a complex number (vec2<f32>)
        let c = u.center + (fragCoord.xy - 0.5 * u.resolution) * scaleFactor;
        escapeValue = get_escape_velocity(c);
    } else {
        // The difference from the reference center in the complex plane:
        // ∆₀ = Y₀ - X₀
        let delta0 = (fragCoord.xy - u.center) * scaleFactor;
        escapeValue = get_escape_velocity_perturb(delta0);
    }

    if (escapeValue == ${MAX_ITERATIONS}) {
        // inside => black
        return vec4f(0.0, 0.0, 0.0, 1.0);
    } else {
        // outside => color = (c, c, 1)
        let col = 1.0 - f32(escapeValue) / f32(${MAX_ITERATIONS});
        return vec4f(col, col, 1.0, 1.0);
    }
}
`;
