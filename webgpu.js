// --------------------------------------
// Code generated by ChatGPT model o1 pro
// --------------------------------------

import { canvas, state } from "./state.js";

/* ------------------------------------------------------------------
 * WEBGPU: 64-bit fractal preview
 * ------------------------------------------------------------------ */

// WEBGPU objects
let gpuContext = null;
let gpuDevice = null;
let gpuPipeline = null;
let gpuUniformBuffer = null;
let gpuBindGroup = null;

/**
 * Initialize WebGPU context/pipeline if supported
 */
export async function initWebGPU() {
    if (!('gpu' in navigator)) {
        console.warn('WebGPU not supported in this browser.');
        return false;
    }

    const adapter = await navigator.gpu.requestAdapter();
    if (!adapter) {
        console.warn('Failed to get GPU adapter.');
        return false;
    }

    gpuDevice = await adapter.requestDevice();
    if (!gpuDevice) {
        console.warn('Failed to request GPU device.');
        return false;
    }

    // Create a WebGPU canvas context from our <canvas>
    gpuContext = canvas.getContext('webgpu');
    if (!gpuContext) {
        console.warn('Could not get WebGPU context.');
        return false;
    }

    const format = navigator.gpu.getPreferredCanvasFormat();
    gpuContext.configure({
        device: gpuDevice,
        format: format,
        alphaMode: 'premultiplied'
    });

    // Create our render pipeline
    gpuPipeline = gpuDevice.createRenderPipeline({
        layout: 'auto',
        vertex: {
            module: gpuDevice.createShaderModule({
                code: wgslVertexShader
            }),
            entryPoint: 'main'
        },
        fragment: {
            module: gpuDevice.createShaderModule({
                code: wgslFragmentShader
            }),
            entryPoint: 'main',
            targets: [{ format }]
        },
        primitive: {
            topology: 'triangle-strip',
            stripIndexFormat: undefined
        }
    });

    // Create a buffer for the uniform data.
    // We'll store centerX, centerY, zoom as f64, plus a little padding, plus resolution as f32x2
    // For simplicity, we just allocate 48 bytes (6 x f64) and only use what we need.
    // Real code should mind alignment carefully if mixing f64 + f32 in a struct.
    gpuUniformBuffer = gpuDevice.createBuffer({
        size: 48, // enough space for 3 f64 + 2 f32 + padding
        usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });

    gpuBindGroup = gpuDevice.createBindGroup({
        layout: gpuPipeline.getBindGroupLayout(0),
        entries: [
            {
                binding: 0,
                resource: {
                    buffer: gpuUniformBuffer
                }
            }
        ]
    });
    return true;
}

/**
 * Render fractal with WebGPU
 */
export function renderFractalWebGPU(scale = 1) {
    if (!gpuDevice || !gpuContext || !gpuPipeline) {
        console.error("gpu context not initialized properly");
        return;
    }

    // We do a small offscreen scale if needed by user’s request
    // but typically, we just draw directly to the canvas size.
    // For a real “downscale” approach, you’d need an intermediate texture.
    // For simplicity, we just treat the entire canvas as final.
    // The user’s “scale” can be accounted for in the uniform (like a multiplier).
    const w = canvas.width;
    const h = canvas.height;

    // Fill our uniform buffer with the current parameters.
    // We'll do layout like this (in 64-bit + 32-bit):
    //   offset 0: centerX (f64)
    //   offset 8: centerY (f64)
    //   offset 16: zoom    (f64)
    //   offset 24: unused/padding (f64)  [so next offset is multiple of 16]
    //   offset 32: resolution.x (f32)
    //   offset 36: resolution.y (f32)
    //
    // This is a simplistic approach. If your device complains about alignment,
    // you may need to add more padding. 
    const uniformArray = new ArrayBuffer(40); 
    const f64View      = new Float64Array(uniformArray);
    const f32View      = new Float32Array(uniformArray);

    f64View[0] = state.x;       // centerX
    f64View[1] = state.y;       // centerY
    f64View[2] = state.zoom;    // zoom
    // f64View[3] = 0 (padding)

    // Then at offset 32 bytes => f32View[8], f32View[9]
    // because each Float64 is 8 bytes => 3*8=24, plus 8 for the padding => 32
    f32View[8] = w * scale;
    f32View[9] = h * scale;

    gpuDevice.queue.writeBuffer(gpuUniformBuffer, 0, uniformArray);

    // Acquire a texture to render to (the canvas)
    const renderView = gpuContext.getCurrentTexture().createView();

    // Build render pass
    const commandEncoder = gpuDevice.createCommandEncoder();
    const passEncoder = commandEncoder.beginRenderPass({
        colorAttachments: [
            {
                view: renderView,
                clearValue: { r: 0, g: 0, b: 0, a: 1 },
                loadOp: 'clear',
                storeOp: 'store',
            },
        ],
    });

    passEncoder.setPipeline(gpuPipeline);
    passEncoder.setBindGroup(0, gpuBindGroup);
    passEncoder.draw(4, 1, 0, 0); // 4 verts => full-screen quad
    passEncoder.end();

    const gpuCommands = commandEncoder.finish();
    gpuDevice.queue.submit([gpuCommands]);
}

/* ---------------------------------------------------------
 * WGSL Shaders
 * --------------------------------------------------------- */

/**
 * A trivial vertex shader for a full-screen triangle-strip.
 */
const wgslVertexShader = /* wgsl */ `
@vertex
fn main(@builtin(vertex_index) vertexIndex : u32) -> @builtin(position) vec4f {
    // We'll draw 2 triangles that cover the entire clip space:
    //   vertexIndex: 0,1,2,3 => positions in a strip
    let x = f32((vertexIndex & 1u) << 1u) - 1.0; // 0->-1, 1->1, 2->-1, 3->1
    let y = f32((vertexIndex & 2u)) - 1.0;      // 0->-1, 1->-1, 2->1, 3->1
    return vec4f(x, y, 0.0, 1.0);
}
`;

/**
 * Fragment shader that uses 64-bit floats for iteration
 * We store uniform data in a struct:
 *   - centerX, centerY, zoom as f64
 *   - resolution as vec2<f32>
 */
const wgslFragmentShader = /* wgsl */ `
enable f64;

struct FractalUniforms {
    centerX   : f64,
    centerY   : f64,
    zoom      : f64,
    padding   : f64,          // keep alignment simple
    resolution: vec2<f32>
};

@group(0) @binding(0)
var<uniform> u : FractalUniforms;

@fragment
fn main(@builtin(position) fragCoord: vec4f) -> @location(0) vec4f {
    // Because we are in normalized device coords, we want a pixel-based coordinate:
    let px = fragCoord.x;
    let py = fragCoord.y;

    let width  = f64(u.resolution.x);
    let height = f64(u.resolution.y);

    // Flip y so it matches CPU approach (top-down)
    let flippedY = f64(height) - f64(py);

    // scale = 4 / (width * zoom)
    let scale = 4.0 / (width * u.zoom);

    // Convert from pixel to fractal coords
    let x0 = u.centerX + (f64(px) - 0.5 * width)  * scale;
    let y0 = u.centerY - (flippedY - 0.5 * height) * scale;

    // Standard Mandelbrot iteration in 64-bit
    var x : f64 = 0.0;
    var y : f64 = 0.0;

    let maxIter = 500;
    var escapeValue = maxIter;

    for (var i = 0; i < maxIter; i = i + 1) {
        let x2 = x*x - y*y + x0;
        let y2 = 2.0 * x*y + y0;
        x = x2;
        y = y2;

        if (x*x + y*y > 4.0) {
            escapeValue = i;
            break;
        }
    }

    if (escapeValue == maxIter) {
        // inside => black
        return vec4f(0.0, 0.0, 0.0, 1.0);
    } else {
        // outside => match CPU color (c, c, 1)
        let c = f32(1.0 - f64(escapeValue) / f64(maxIter));
        return vec4f(c, c, 1.0, 1.0);
    }
}
`;
